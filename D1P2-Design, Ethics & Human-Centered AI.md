<!--
author:   Sabbir Rifat
email:    a.rifat@ovgu.de
version:  1.0.0
language: en
narrator: US English Female

icon: https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/ChatGPT_logo.svg/1024px-ChatGPT_logo.svg.png

comment:  Day 1 - Presentation 2: Design, Ethics & Human-Centered AI
          Critical examination of AI agents through ethical and human-centered lens

-->

# âš–ï¸ Design, Ethics & Human-Centered AI

> **Welcome to Presentation 2!**
> 
> Now that we understand what AI agents are, let's critically examine how to use them responsibly, ethically, and in ways that truly serve human needs.

## ðŸ“‹ Learning Outcomes

By the end of this session, you will be able to:

- [x] Apply human-centered design principles to AI agent implementation
- [x] Identify and address ethical concerns (bias, transparency, accountability)
- [x] Critically evaluate when AI agents support vs. replace human thinking
- [x] Assess pros and cons of AI agents in your academic context
- [x] Make informed decisions about AI adoption in your institution

---

## ðŸ§­ The Critical Question

```ascii
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                            â•‘
â•‘        Should we use AI agents?            â•‘
â•‘                                            â•‘
â•‘              â¬‡ï¸  NOT YET  â¬‡ï¸               â•‘
â•‘                                            â•‘
â•‘       First ask: SHOULD WE?                â•‘
â•‘              HOW SHOULD WE?                â•‘
â•‘              WHAT ARE THE RISKS?           â•‘
â•‘                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### ðŸŽ¯ Our Approach Today

**We will NOT hype AI agents.**

Instead, we will:
- ðŸ¤” Think critically
- âš–ï¸ Balance benefits and risks
- ðŸ‘¥ Put humans first
- ðŸ” Question assumptions
- ðŸ›¡ï¸ Protect what matters

---

## ðŸŒŸ What is Human-Centered AI?

### The Core Philosophy

**Human-Centered AI** means designing AI systems that:

```ascii
    ðŸŽ¯ SERVE HUMAN NEEDS
           â†“
    ðŸ‘¥ AUGMENT (not replace) human capabilities
           â†“
    ðŸ” REMAIN TRANSPARENT & UNDERSTANDABLE
           â†“
    âš–ï¸ RESPECT HUMAN DIGNITY & RIGHTS
           â†“
    ðŸ¤ ENABLE HUMAN CONTROL & OVERSIGHT
```

### The Difference

| âŒ Technology-Centered | âœ… Human-Centered |
|----------------------|------------------|
| "What can AI do?" | "What do humans need?" |
| "Let's automate everything!" | "Where does automation truly help?" |
| "AI knows best" | "Humans decide, AI assists" |
| "Faster is always better" | "Better is defined by human values" |
| "Replace expensive humans" | "Empower capable humans" |

### ðŸŽ“ Academic Example: Two Approaches to Student Advising

#### âŒ **Technology-Centered Approach**

**University decides:** "AI agent will handle all advising appointments"

**What happens:**
- Students forced to interact with AI
- No option for human advisor
- System optimized for efficiency, not student wellbeing
- Struggling students get automated responses

**Result:** Students feel unheard and unsupported ðŸ˜ž

#### âœ… **Human-Centered Approach**

**University decides:** "AI agent will support advisors and students"

**What happens:**
- AI handles routine questions (course prerequisites, deadlines)
- Identifies students who need human attention
- Advisors focus on complex, personal issues
- Students choose their interaction method

**Result:** Better support for more students ðŸ˜Š

---

## ðŸŽ¯ Quiz Time! Understanding Human-Centered Design

Which scenario demonstrates human-centered AI design?

[( )] AI system automatically grades all essays without professor review
[(X)] AI system flags potential issues in essays for professor to review and provide personalized feedback
[( )] AI system replaces office hours with automated Q&A
[( )] AI system makes all curriculum decisions based on data

---

## ðŸ—ï¸ Human-Centered Design Principles

### 1. ðŸ‘¤ **Put People First**

**Principle:** Start with human needs, not technology capabilities

**In Practice - Research Example:**

**âŒ Wrong:** "We have AI that can analyze 10,000 papers per day. Let's use it!"

**âœ… Right:** "Researchers struggle to stay current with literature. How can AI help with this specific problem?"

### Real Scenario: Dr. Mariam's Challenge

**Dr. Mariam** (History Professor) says:
> "I don't need to read 10,000 papers. I need to deeply understand 50 relevant ones and teach my students critical analysis skills."

**Human-centered solution:**
- AI curates and ranks papers by relevance
- Highlights key debates and perspectives
- Suggests connections between sources
- **Dr. Mariam** reads, analyzes, and teaches critical thinking

**Time saved:** Used for deeper engagement, not just "more"

---

### 2. ðŸ” **Maintain Transparency**

**Principle:** People should understand how AI makes decisions

```ascii
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     THE TRANSPARENCY SPECTRUM           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  ðŸš« BLACK BOX                           â”‚
â”‚  "AI decided. Don't ask why."           â”‚
â”‚                                         â”‚
â”‚  âš ï¸  OPAQUE                             â”‚
â”‚  "AI uses complex algorithms."          â”‚
â”‚                                         â”‚
â”‚  ðŸ“Š INTERPRETABLE                       â”‚
â”‚  "AI ranked these based on X, Y, Z."    â”‚
â”‚                                         â”‚
â”‚  âœ… TRANSPARENT                         â”‚
â”‚  "Here's exactly how AI reached         â”‚
â”‚   this conclusion, and here's the       â”‚
â”‚   data it used."                        â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸŽ“ University Example: Admissions Decision

**Scenario:** University uses AI to help evaluate applications

#### âŒ **Non-Transparent Approach**

"The AI scored this applicant 6.7/10"

- **Why that score?** Unknown
- **What factors mattered?** Mystery
- **Can we contest it?** No basis to do so
- **Legal implications?** Potentially serious

#### âœ… **Transparent Approach**

"The AI scored this applicant 6.7/10 based on:
- Academic record: 7.5/10 (GPA, test scores)
- Essays: 6.0/10 (clarity, originality)
- Recommendations: 7.0/10 (strength, specificity)
- Activities: 6.5/10 (leadership, commitment)

**Human reviewer** examines score, context, and makes final decision with full understanding."

---

### 3. ðŸ¤ **Enable Human Control**

**Principle:** Humans must remain in control and able to override AI

### The Control Spectrum

```markdown
| Level | Human Role | AI Role | Example |
|-------|-----------|---------|---------|
| ðŸŸ¢ **Full Control** | Decides everything | Provides information | AI shows research papers; professor selects |
| ðŸŸ¡ **Shared Control** | Approves AI suggestions | Recommends actions | AI suggests course topics; professor approves |
| ðŸŸ  **Monitored Automation** | Can intervene | Executes with oversight | AI schedules rooms; staff can override |
| ðŸ”´ **Full Automation** | Informed after fact | Decides and acts | AI automatically fails students âŒ |
```

**Rule for Academia:** Never use ðŸ”´ Full Automation for consequential decisions!

### Real Scenario: Plagiarism Detection

**Georgian University Case Study:**

**Old system (ðŸ”´ Full Automation):**
- AI automatically marks assignments as plagiarized
- Student gets zero
- Professor sees result later

**Problems:**
- AI flagged student quoting course readings properly
- AI couldn't understand Georgian language nuances
- Student's grade harmed unfairly

**New system (ðŸŸ¡ Shared Control):**
- AI flags potential issues
- Professor reviews each case
- Considers context, language, discipline conventions
- **Professor** makes final decision

**Result:** More accurate, fairer outcomes

---

### 4. ðŸŽ¨ **Design for Dignity**

**Principle:** AI should respect and enhance human dignity

**What this means:**
- ðŸš« Don't reduce people to data points
- ðŸš« Don't make people feel worthless
- âœ… Acknowledge human complexity
- âœ… Preserve meaningful human interaction
- âœ… Support human growth and learning

### Example: Student Feedback

#### âŒ **Dignity-Harming Approach**

AI feedback on student essay:

> "This essay is poorly written. Score: 3/10. You ranked in bottom 5% of class. AI suggests you are not suited for this subject."

**Impact:** Student feels humiliated, loses confidence, may drop out

#### âœ… **Dignity-Preserving Approach**

AI-assisted feedback reviewed by professor:

> "Your essay shows good effort in tackling complex ideas. Here are specific areas to strengthen:
> 
> 1. Thesis clarity - let's work on making your main argument more explicit
> 2. Evidence integration - you have good sources, let's connect them more clearly
> 3. Conclusion - try restating why this matters
>
> I see potential here. Let's discuss in office hours. - Prof. Levan"

**Impact:** Student has path forward, maintains dignity, stays engaged

---

## ðŸŽ¯ Quiz Time! Apply Design Principles

Your university wants to use AI to predict which students might drop out. Which approach is most human-centered?

[( )] AI automatically sends warning letters to low-scoring students
[( )] AI creates a public dashboard ranking students by dropout risk
[(X)] AI privately alerts advisors to check in personally with students showing concerning patterns
[( )] AI emails students their dropout probability percentage

---

## âš–ï¸ Key Ethical Concerns

### 1. ðŸŽ­ **Bias and Fairness**

**The Problem:** AI learns from historical data, which contains human biases

```ascii
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         HOW BIAS ENTERS AI               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚  ðŸ“Š BIASED DATA                          â”‚
â”‚  (Historical discrimination patterns)    â”‚
â”‚           â†“                              â”‚
â”‚  ðŸ¤– AI LEARNS PATTERNS                   â”‚
â”‚  (Reproduces biases automatically)       â”‚
â”‚           â†“                              â”‚
â”‚  âš¡ BIASED DECISIONS                     â”‚
â”‚  (Amplifies existing inequalities)       â”‚
â”‚           â†“                              â”‚
â”‚  ðŸ”„ FEEDBACK LOOP                        â”‚
â”‚  (Creates more biased data)              â”‚
â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸŽ“ Real Academic Example: Hiring Bias

**Scenario:** University uses AI to screen faculty applications

**What happened (Real story from international university):**

- AI trained on 10 years of hiring data
- Historical hires were 75% male in engineering
- AI learned: "male candidates are better fits"
- AI automatically downranked female applicants
- **Result:** Perpetuated gender inequality

**Root cause:** Not the AI itself, but biased historical data

### ðŸ‡¬ðŸ‡ª Georgian Context Example

**Scenario:** AI grading system for essays

**Potential bias:**
- Trained mostly on Tbilisi university data
- May disadvantage students from regional universities
- May not understand regional dialects or expressions
- Could favor writing styles common in capital

**Solution:** 
- Diverse training data from all regions
- Human review of AI assessments
- Regular bias audits
- Multiple assessment methods

---

### 2. ðŸ” **Privacy and Data Protection**

**The Concern:** AI agents need data to function, but whose data? How is it used?

### Data Privacy Principles

```markdown
| Principle | What It Means | Academic Example |
|-----------|---------------|------------------|
| ðŸŽ¯ **Purpose Limitation** | Only collect data for specific, stated purposes | Collect grades for advising, not for unrelated research |
| ðŸ“Š **Data Minimization** | Collect only what's necessary | Need student performance data, not their medical history |
| ðŸ”’ **Security** | Protect data from unauthorized access | Encrypt student records, limit access |
| â° **Retention Limits** | Don't keep data forever | Delete after student graduates + required period |
| ðŸ‘¤ **User Rights** | People can access, correct, delete their data | Students can see and correct their AI profile |
```

### ðŸš¨ Real Scenario: Privacy Violation

**What happened:**

Georgian university implemented "student success" AI:
- Tracked students' library visits
- Monitored online learning logins
- Analyzed social media (if public)
- Combined with grade data

**Student discovers:**
- AI created detailed behavioral profile
- Shared with multiple departments
- Students never clearly consented
- No way to see or correct their profile

**Outcome:**
- Student complaints
- Privacy authority investigation
- System suspended
- University fined

**Lesson:** Transparency and consent are not optional!

---

### 3. ðŸŽ“ **Academic Integrity**

**The Question:** Does AI help or harm genuine learning?

### The Spectrum of Use

```ascii
âœ… ENHANCES LEARNING          |  âŒ UNDERMINES LEARNING
                               |
ðŸ“š Research assistance        |  ðŸš« Essay generation
ðŸ” Finding sources            |  ðŸš« Automated homework
ðŸ’¡ Brainstorming ideas        |  ðŸš« Taking exams via AI
âœï¸ Editing feedback           |  ðŸš« Pretending AI work is yours
ðŸ“Š Data analysis support      |  ðŸš« Fabricating research data
ðŸ—£ï¸ Language learning help     |  ðŸš« All translation with no learning
```

### Real Scenario: The Cheating Dilemma

**Professor Nino's Class (Literature):**

**Assignment:** "Write analysis of Georgian modernist poetry"

**Student A:** Uses AI to:
- Generate complete essay
- Submits without reading sources
- Learns nothing

**Student B:** Uses AI to:
- Find lesser-known poems
- Check understanding of complex passages
- Get feedback on draft argument
- Write final essay themselves

**Question:** Both used AI. One cheated, one learned. How do we tell the difference?

**Answer:** **Intent, transparency, and learning outcomes matter**

---

### 4. âš–ï¸ **Accountability**

**The Critical Question:** When AI makes a mistake, who is responsible?

### The Accountability Gap

```ascii
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    WHO IS RESPONSIBLE WHEN AI FAILS?    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  ðŸ¤– The AI?                             â”‚
â”‚  â†’ No - it's a tool, not a person       â”‚
â”‚                                         â”‚
â”‚  ðŸ’» The Developer?                      â”‚
â”‚  â†’ Maybe - but they're far away         â”‚
â”‚                                         â”‚
â”‚  ðŸ¢ The University?                     â”‚
â”‚  â†’ Partly - they chose to use it        â”‚
â”‚                                         â”‚
â”‚  ðŸ‘¤ The User (Professor/Staff)?         â”‚
â”‚  â†’ Partly - they applied it             â”‚
â”‚                                         â”‚
â”‚  ðŸ“‹ Clear Answer?                       â”‚
â”‚  â†’ Often missing! This is the gap.      â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ðŸŽ“ Real Case: Grade Appeal

**What happened:**

- AI agent assists with grading
- Student receives failing grade
- AI made calculation error
- Student appeals: "AI was wrong!"
- University: "Who do we hold accountable?"

**Options:**

1. **Blame the student?** âŒ They didn't use AI
2. **Blame the professor?** âš ï¸ They trusted the AI
3. **Blame the AI company?** âš ï¸ They sold the tool
4. **Blame the university?** âš ï¸ They implemented it

**Right answer:** **Clear accountability structure must exist BEFORE using AI**

### Accountability Framework

```markdown
| Decision Type | AI Role | Human Responsible | Review Process |
|--------------|---------|-------------------|----------------|
| Course grades | Assists calculation | Professor verifies | Student can appeal to dean |
| Admissions | Ranks applications | Committee decides | Appeals board reviews |
| Research misconduct | Flags patterns | Ethics board investigates | Full due process |
| Resource allocation | Suggests optimization | Administration approves | Faculty senate reviews |
```

---

## ðŸŽ¯ Quiz Time! Ethical Reasoning

A university uses AI to monitor student emails for mental health crisis keywords and automatically alerts counseling services. What's the PRIMARY ethical concern?

[( )] The AI might make technical errors
[(X)] Privacy violation without informed consent
[( )] The AI might miss some cases
[( )] Cost of the AI system

---

## ðŸ§  The Big Question: Minds or Tools?

### Do AI Agents Think?

**Three Perspectives:**

#### 1. ðŸ¤– **"AI Has Artificial Minds"**

**View:** AI agents genuinely understand and reason

**Arguments:**
- They solve problems creatively
- They learn from experience
- They generate novel ideas
- They pass many intelligence tests

**Counterargument:** 
- They don't truly "understand" - they pattern-match
- They lack consciousness
- They can't feel or genuinely care

---

#### 2. ðŸ”§ **"AI Are Sophisticated Tools"**

**View:** AI agents are powerful instruments with no real understanding

**Arguments:**
- They manipulate symbols without meaning
- They can't generalize beyond training
- They lack genuine creativity
- They're deterministic machines

**Counterargument:**
- The output seems indistinguishable from understanding
- Does it matter if they "truly" understand?

---

#### 3. ðŸ¤ **"AI Are Partners" (Most Practical View)**

**View:** Doesn't matter if they "think" - focus on effective collaboration

**Arguments:**
- Treat them as cognitive partners
- Combine their strengths with human strengths
- Focus on outcomes, not philosophy
- Design for effective human-AI teaming

**This is the approach we recommend for academia**

---

### ðŸŽ“ What This Means for Education

```ascii
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                       â•‘
â•‘   AI AGENTS DON'T REPLACE:            â•‘
â•‘                                       â•‘
â•‘   ðŸŽ“ Critical thinking                â•‘
â•‘   ðŸ’¡ Creativity and innovation        â•‘
â•‘   â¤ï¸  Empathy and care                â•‘
â•‘   âš–ï¸  Ethical judgment                â•‘
â•‘   ðŸ¤ Human relationships              â•‘
â•‘   ðŸŽ¨ Original synthesis               â•‘
â•‘                                       â•‘
â•‘   AI AGENTS CAN AUGMENT:              â•‘
â•‘                                       â•‘
â•‘   ðŸ“Š Information processing           â•‘
â•‘   ðŸ” Pattern recognition              â•‘
â•‘   âš¡ Repetitive tasks                 â•‘
â•‘   ðŸ“š Knowledge organization           â•‘
â•‘   ðŸ’» Technical execution              â•‘
â•‘                                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Real Example: Teaching Philosophy

**Professor Giorgi teaches Ethics:**

**âŒ Wrong approach:** "AI can teach ethics now. I'm not needed."

**âœ… Right approach:** "AI can:
- Present ethical scenarios quickly
- Show diverse perspectives
- Check understanding of concepts

**But I must:**
- Guide moral reasoning development
- Model ethical thinking process
- Create safe space for difficult discussions
- Help students apply ethics to real life
- Be present for genuine dialogue"

**Result:** More time for what matters most - human development

---

## âš–ï¸ Pros and Cons: The Honest Assessment

### âœ… Benefits of AI Agents in Academia

#### 1. â° **Efficiency Gains**

**Real data from pilot universities:**
- Administrative tasks: 40% time reduction
- Literature reviews: 60% faster initial screening
- Routine student questions: 24/7 instant response

**But:** Efficiency â‰  Better outcomes automatically

---

#### 2. ðŸ“Š **Scale and Access**

**Example:** One professor can now:
- Provide initial feedback to 200 students
- Monitor learning analytics across courses
- Maintain office hours support overnight

**But:** At what cost to depth and personal connection?

---

#### 3. ðŸŽ¯ **Personalization**

**Possibility:** AI can adapt to each student's:
- Learning pace
- Preferred style
- Knowledge gaps
- Interests

**But:** Risk of algorithmic filter bubbles

---

#### 4. ðŸ” **Data-Driven Insights**

**Examples:**
- Identify struggling students early
- Spot curriculum gaps
- Understand learning patterns
- Evidence-based improvements

**But:** Numbers don't capture everything important

---

### âŒ Risks and Drawbacks

#### 1. ðŸŽ­ **Dehumanization**

**Risk:** Students become data points

**Real concern:**
- Reduced face-to-face interaction
- Loss of mentorship relationships
- Students feel processed, not educated
- Education becomes transactional

**Story from Georgian University:**

> "I tried to discuss my grandmother's illness with my advisor, but was directed to the AI chatbot. The bot gave me policy information. What I needed was human understanding and flexibility. I felt like a problem to be solved, not a person to be supported." - Student testimonial

---

#### 2. ðŸ§  **Skill Atrophy**

**Risk:** Over-reliance on AI reduces human capabilities

**Concerns:**
- Students don't develop critical thinking if AI answers everything
- Researchers lose literature analysis skills
- Academics stop developing intuition
- "Use it or lose it" applies to cognitive skills

**Real scenario:**
- Students can't write without AI
- Lost ability to formulate own ideas
- Struggle when AI unavailable (exams)

---

#### 3. ðŸ’¸ **Cost and Inequality**

**Reality check:**

**Costs:**
- AI systems: â‚¬20,000 - â‚¬500,000/year
- Training: Time and resources
- IT infrastructure: Upgrades needed
- Maintenance: Ongoing expense

**Result:**
- Wealthy universities pull ahead
- Poor universities fall behind
- Inequality widens
- Two-tier system emerges

---

#### 4. ðŸ”’ **Vendor Lock-in**

**Risk:** Dependence on private companies

**Concerns:**
- University data in corporate servers
- Subscription costs increase yearly
- Can't switch systems easily
- Features changed without consent
- Academic freedom compromised?

---

#### 5. âš ï¸ **Errors and Hallucinations**

**Reality:** AI agents make mistakes confidently

**Real examples:**
- AI cites nonexistent research papers
- AI invents facts that sound plausible
- AI misinterprets context
- AI gives outdated information

**Danger:** Users trust AI more than they should

**Story:** Professor assigned AI-suggested readings. Three papers didn't exist. Students wasted hours searching. Trust damaged.

---

## ðŸŽ¯ Final Quiz: Critical Analysis

Your university wants to implement AI agents to automatically generate personalized study plans for every student. What should be your FIRST question?

[( )] How much does it cost?
[( )] Which AI vendor is best?
[(X)] What specific problem are we trying to solve, and is AI the right solution?
[( )] How quickly can we implement it?

---

## ðŸ’¡ Decision Framework: Should We Use AI Here?

### The 7 Critical Questions

Before implementing any AI agent, ask:

```ascii
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    THE AI IMPLEMENTATION CHECKLIST      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  âœ“ 1. NEED                              â”‚
â”‚     What specific problem does this     â”‚
â”‚     solve better than current methods?  â”‚
â”‚                                         â”‚
â”‚  âœ“ 2. HUMAN-CENTERED                    â”‚
â”‚     Does this serve human needs         â”‚
â”‚     or just use technology for its      â”‚
â”‚     own sake?                           â”‚
â”‚                                         â”‚
â”‚  âœ“ 3. TRANSPARENCY                      â”‚
â”‚     Can we explain how it works?        â”‚
â”‚     Can users understand it?            â”‚
â”‚                                         â”‚
â”‚  âœ“ 4. CONTROL                           â”‚
â”‚     Do humans remain in control?        â”‚
â”‚     Can we override decisions?          â”‚
â”‚                                         â”‚
â”‚  âœ“ 5. ETHICS                            â”‚
â”‚     Have we addressed bias, privacy,    â”‚
â”‚     fairness, accountability?           â”‚
â”‚                                         â”‚
â”‚  âœ“ 6. SUSTAINABILITY                    â”‚
â”‚     Can we maintain this long-term?     â”‚
â”‚     What if funding ends?               â”‚
â”‚                                         â”‚
â”‚  âœ“ 7. ALTERNATIVES                      â”‚
â”‚     Have we considered non-AI           â”‚
â”‚     solutions?                          â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example Application

**Proposal:** AI agent to answer student emails

**Question 1 - Need:**
âœ… Students ask same questions repeatedly
âœ… Staff overwhelmed during peak times
âš ï¸ But: Many questions need human judgment

**Question 2 - Human-centered:**
âœ… Frees staff for complex issues
âš ï¸ Need to ensure students can still reach humans

**Question 3 - Transparency:**
âœ… Can explain it's AI in email signature
âœ… Can show how it finds answers
âš ï¸ Need to be clear about limitations

**Question 4 - Control:**
âœ… Staff reviews AI responses
âœ… Can intervene anytime
âœ… Students can escalate to human

**Question 5 - Ethics:**
âš ï¸ Need privacy policy for email content
âš ï¸ Must handle sensitive topics carefully
âš ï¸ Ensure equal quality for all students

**Question 6 - Sustainability:**
âš ï¸ Budget for 3+ years?
âš ï¸ Training for staff turnover?
âš ï¸ Backup plan if system fails?

**Question 7 - Alternatives:**
ðŸ¤” Could we: improve FAQ page, create video guides, redistribute staff, hire student assistants?

**Decision:** Proceed cautiously with pilot program, clear human oversight, and regular evaluation.

---

## ðŸŽ¨ Interactive Activity: Ethical Analysis

> **Let's practice critical evaluation!**

### ðŸ‘¥ Small Group Exercise (20 minutes)

**Instructions:**

1. Form groups of 3-4 people
2. Choose ONE scenario below
3. Analyze using the ethical framework
4. Present your conclusions

---

### Scenarios

#### Scenario A: Automated Attendance Monitoring

**Proposal:** 
University wants to use AI with cameras to automatically track student attendance in lectures. System uses facial recognition.

**Your task:** Analyze ethical implications

**Consider:**
- Privacy: Is continuous monitoring acceptable?
- Consent: Can students opt out?
- Accuracy: What if system misidentifies students?
- Purpose: Why track attendance? Is this the best way?
- Culture: Does this fit academic culture?
- Alternatives: Other ways to encourage attendance?

---

#### Scenario B: Predictive Career Advising

**Proposal:**
AI agent analyzes student performance, personality tests, and labor market data to recommend career paths. Students receive "career match score" for different professions.

**Your task:** Identify risks and benefits

**Consider:**
- Bias: Historical labor market discrimination in data?
- Determinism: Should AI predict futures?
- Agency: Does this limit student choices?
- Accuracy: Can AI predict career success?
- Transparency: Can students understand recommendations?
- Human role: What's the advisor's role?

---

#### Scenario C: Research Misconduct Detection

**Proposal:**
AI agent continuously scans all research output for potential plagiarism, data fabrication, and ethical violations. Automatically flags suspicious cases to ethics committee.

**Your task:** Evaluate appropriateness

**Consider:**
- Trust: Does this assume guilt?
- False positives: What about innocent mistakes?
- Academic freedom: Does surveillance chill research?
- Due process: How are flagged researchers treated?
- Transparency: Do researchers know they're monitored?
- Effectiveness: Will this catch real problems or just create fear?

---

### ðŸ“ Analysis Template

Use this structure:

```markdown
**Scenario:** [Which one?]

**Primary Benefits:**
1. [What's good about this?]
2. [Who benefits and how?]

**Primary Risks:**
1. [What could go wrong?]
2. [Who might be harmed?]

**Ethical Concerns:**
- Privacy: [Your assessment]
- Fairness: [Your assessment]  
- Transparency: [Your assessment]
- Accountability: [Your assessment]

**Human-Centered Questions:**
- Does this serve genuine human needs?
- Are there better alternatives?
- Can we maintain human dignity and control?

**Our Recommendation:**
â–¡ Proceed as planned
â–¡ Proceed with modifications: [What changes?]
â–¡ Pilot test first: [What should we test?]
â–¡ Do not proceed: [Why not?]

**Key Safeguards Needed:**
1. [Specific protection]
2. [Specific protection]
3. [Specific protection]
```

---

## ðŸŒˆ Key Takeaways

### What We Learned Today

```ascii
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   ETHICS & HUMAN-CENTERED AI - SUMMARY    â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                           â•‘
â•‘  ðŸ‘¥ Put people first, technology second   â•‘
â•‘                                           â•‘
â•‘  ðŸ” Demand transparency and               â•‘
â•‘     accountability                        â•‘
â•‘                                           â•‘
â•‘  âš–ï¸ Balance benefits against real risks   â•‘
â•‘                                           â•‘
â•‘  ðŸ›¡ï¸ Protect privacy, dignity, and         â•‘
â•‘     academic freedom                      â•‘
â•‘                                           â•‘
â•‘  ðŸ¤” Question assumptions and hype         â•‘
â•‘                                           â•‘
â•‘  ðŸ¤ Design for human-AI collaboration,    â•‘
â•‘     not replacement                       â•‘
â•‘                                           â•‘
â•‘  âœ… Use systematic ethical analysis       â•‘
â•‘     before implementation                 â•‘
â•‘                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### The Golden Rules

1. **ðŸŽ¯ Technology serves people, not the reverse**
   - Always start with human needs

2. **ðŸ” Transparency is non-negotiable**
   - If you can't explain it, don't use it

3. **ðŸ‘¤ Humans must remain in control**
   - Especially for consequential decisions

4. **âš–ï¸ Benefits must clearly outweigh risks**
   - And risks must be actively managed

5. **ðŸ¤ AI augments, never replaces, human judgment**
   - In matters of education and ethics

6. **ðŸ“‹ Accountability must be clear**
   - Before, not after, problems occur

7. **ðŸ›¡ï¸ When in doubt, protect human dignity**
   - Some things matter more than efficiency

---

## ðŸŽ“ Academic Integrity Guidelines

### Recommended Policy Framework

**For Your Institution:**

#### âœ… **Acceptable AI Use**

**Teaching:**
- Generating diverse examples
- Creating practice problems
- Providing feedback on drafts
- Suggesting resources
- Adapting content for accessibility

**Research:**
- Literature search and organization
- Data cleaning and preparation
- Preliminary analysis
- Citation formatting
- Translation assistance

**Learning:**
- Understanding complex concepts
- Checking work for errors
- Brainstorming ideas
- Learning new skills
- Practicing language

---

#### âš ï¸ **Requires Disclosure**

**Students must disclose when:**
- AI generates any portion of submitted work
- AI assists with data analysis
- AI translates significant content
- AI provides structural assistance

**Faculty must disclose when:**
- AI assists with grading
- AI generates course materials
- AI monitors student activity
- AI makes recommendations about students

---

#### âŒ **Unacceptable AI Use**

**Never acceptable:**
- Submitting AI-generated work as your own
- Using AI during exams without permission
- AI writing full research papers
- Bypassing learning objectives
- Fabricating data with AI
- Violating privacy with AI tools

---

## ðŸ“Š Comparative Analysis: AI Agents in Different Contexts

### When AI Works Well vs. When It Doesn't

| Context | âœ… AI Works Well | âŒ AI Struggles |
|---------|-----------------|----------------|
| **Student Questions** | "What's the deadline?" "Where's room 305?" | "I'm feeling overwhelmed" "Should I change my major?" |
| **Grading** | Multiple choice, coding syntax, math problems | Essays, creative work, critical analysis |
| **Research** | Finding papers, organizing citations | Evaluating significance, theoretical innovation |
| **Advising** | Tracking requirements, suggesting courses | Career counseling, personal crises |
| **Administration** | Scheduling, data entry, reminders | Policy interpretation, special cases |

---

## ðŸŽ¯ Final Comprehensive Quiz

### Question 1: Ethical Priority

A new AI system would save 10 hours per week but requires monitoring all student online activity. What's the ethical priority?

[( )] Implement immediately - efficiency is critical
[( )] Calculate cost-benefit ratio first
[(X)] Evaluate privacy implications and alternatives before deciding
[( )] Let students vote on whether to use it

---

### Question 2: Human-Centered Design

Which statement BEST reflects human-centered AI design?

[( )] "We implemented the most advanced AI available"
[(X)] "We identified a problem, considered solutions, and chose AI where it genuinely helps"
[( )] "We automated everything possible to save money"
[( )] "We adopted AI because other universities are using it"

---

### Question 3: Accountability

An AI grading assistant makes an error that affects a student's final grade. Who should be primarily responsible?

[( )] The AI company that made the software
[( )] The IT department that installed it
[(X)] The professor who used it and verified results
[( )] The student for not double-checking

---

### Question 4: Real-World Application

Your department wants to use AI to predict which students will fail courses and automatically enroll them in remedial programs. What's your PRIMARY concern?

[( )] The technical accuracy of predictions
[( )] The cost of the AI system
[(X)] Student agency - removing their choice and potentially creating self-fulfilling prophecy
[( )] The time required to implement

---

## ðŸ”® Looking Ahead: Responsible AI Adoption

### A Roadmap for Your Institution

```ascii
PHASE 1: PREPARATION (3-6 months)
â”œâ”€ Form ethics committee
â”œâ”€ Develop AI policy framework
â”œâ”€ Train staff on responsible AI
â”œâ”€ Identify high-value, low-risk use cases
â””â”€ Establish evaluation metrics

PHASE 2: PILOT TESTING (6-12 months)
â”œâ”€ Start with 1-2 small projects
â”œâ”€ Extensive monitoring and feedback
â”œâ”€ Document lessons learned
â”œâ”€ Adjust policies based on experience
â””â”€ Build institutional knowledge

PHASE 3: CAREFUL EXPANSION (1-2 years)
â”œâ”€ Scale what works
â”œâ”€ Abandon what doesn't
â”œâ”€ Continuous ethical review
â”œâ”€ Regular stakeholder consultation
â””â”€ Maintain human oversight

ONGOING: EVALUATION & ADAPTATION
â”œâ”€ Annual policy review
â”œâ”€ Bias audits
â”œâ”€ User satisfaction surveys
â”œâ”€ Impact assessments
â””â”€ Stay current with developments
```

---

## ðŸ’­ Reflection Questions

Take 5 minutes to consider:

1. **Personal stance:**
   - How do you feel about AI agents after today's session?
   - What concerns you most?
   - What excites you most?

2. **Your context:**
   - Where could AI genuinely help in your work?
   - Where would AI be inappropriate?
   - What safeguards does your institution need?

3. **Action items:**
   - What will you do differently?
   - What conversations will you start?
   - What policies need attention?

---

## ðŸ“š Additional Resources

### Essential Reading

1. **"Ethics of AI in Education"** - UNESCO Guidelines (2024)
2. **"Human-Centered AI: A Practical Framework"** - Stanford HAI
3. **"Algorithmic Fairness and Bias"** - EU AI Act Guidelines
4. **"Privacy in the Age of AI"** - Data Protection Authority

### Case Studies

- ðŸ‡¬ðŸ‡ª Georgian University AI Implementations
- ðŸ‡ªðŸ‡º European Academic AI Policies
- ðŸŒ International Best Practices

### Tools for Ethical Assessment

- AI Ethics Canvas
- Algorithmic Impact Assessment Template
- Privacy Impact Assessment Guide
- Bias Testing Frameworks

---

## ðŸ¤ Community of Practice

### Join the Conversation

**Discussion Forum Topics:**

1. ðŸ’¬ Share your AI concerns and questions
2. ðŸ“‹ Discuss policy development
3. ðŸ” Ethical dilemmas you're facing
4. âœ… Success stories and lessons learned
5. ðŸ› ï¸ Tool recommendations and warnings

**Monthly Office Hours:**
- Topic-specific sessions
- Q&A with experts
- Peer learning groups

---

## ðŸŽ¬ Summary: The Balanced View

### What AI Agents ARE:

- âœ… Powerful tools for specific tasks
- âœ… Potential efficiency enhancers
- âœ… Support systems for human work
- âœ… Opportunities for innovation

### What AI Agents ARE NOT:

- âŒ Magical solutions to all problems
- âŒ Replacements for human judgment
- âŒ Always accurate or unbiased
- âŒ Appropriate for every context

### Our Responsibility:

```ascii
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                        â•‘
â•‘    As academic professionals,          â•‘
â•‘    we must be:                         â•‘
â•‘                                        â•‘
â•‘    ðŸ¤” CRITICAL not cynical             â•‘
â•‘    ðŸ” CURIOUS not credulous            â•‘
â•‘    âš–ï¸ BALANCED not biased              â•‘
â•‘    ðŸ›¡ï¸ PROTECTIVE of human values       â•‘
â•‘    ðŸš€ OPEN to genuine benefits         â•‘
â•‘    âš ï¸ CAUTIOUS about risks             â•‘
â•‘                                        â•‘
â•‘    We adopt AI thoughtfully,           â•‘
â•‘    not reflexively.                    â•‘
â•‘                                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ðŸ”œ Coming Up Next

### Presentation 3: Practical AI Agent Use + Workshop

**What to expect:**

- ðŸ› ï¸ Hands-on demonstrations
- ðŸ’» No-code/low-code AI agent tools
- ðŸŽ¨ Design your own AI agent concept
- ðŸ’¬ Group discussions and problem-solving
- âš¡ Real tools you can use immediately

**Prepare to:**
- Think about a specific use case from your work
- Consider ethical implications
- Be ready to experiment (safely!)
- Share ideas with colleagues

**Take a 15-minute break!** â˜•

---

## ðŸ™ Thank You!

**You've completed Presentation 2!**

You now understand:
- âœ… Human-centered AI design principles
- âœ… Critical ethical concerns (bias, privacy, accountability)
- âœ… How to balance benefits and risks
- âœ… When AI augments vs. when it should not replace human judgment
- âœ… Framework for responsible AI adoption

**Most importantly:** You have the critical thinking tools to evaluate AI responsibly.

### Remember:

> "The question is not whether we CAN use AI,
> but whether we SHOULD,
> and if so, HOW to do it responsibly."

**Ready for hands-on practice?** ðŸš€

---

### ðŸ’¬ Your Feedback Matters

Please share:
- What was most valuable?
- What needs clarification?
- What concerns remain?
- Suggestions for improvement?

**Contact:** training@university.ge

---

*Training Program for Georgian Academic Staff | Day 1, Session 2 | 2024*